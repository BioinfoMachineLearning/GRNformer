LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]
/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Traceback (most recent call last):
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py", line 38, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 645, in _fit_impl
    self._run(model, ckpt_path=self.ckpt_path)
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 1098, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 1177, in _run_stage
    self._run_train()
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 1200, in _run_train
    self.fit_loop.run()
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py", line 267, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/loops/epoch/training_epoch_loop.py", line 214, in advance
    batch_output = self.batch_loop.run(kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(optimizers, kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/optimizer_loop.py", line 200, in advance
    result = self._run_optimization(kwargs, self._optimizers[self.optim_progress.optimizer_position])
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/optimizer_loop.py", line 247, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, kwargs.get("batch_idx", 0), closure)
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/optimizer_loop.py", line 357, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 1342, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/core/module.py", line 1661, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/core/optimizer.py", line 169, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py", line 234, in optimizer_step
    return self.precision_plugin.optimizer_step(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py", line 121, in optimizer_step
    return optimizer.step(closure=closure, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/optim/optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/optim/optimizer.py", line 33, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/optim/adam.py", line 121, in step
    loss = closure()
           ^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py", line 107, in _wrap_closure
    closure_result = closure()
                     ^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/optimizer_loop.py", line 147, in __call__
    self._result = self.closure(*args, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/optimizer_loop.py", line 133, in closure
    step_output = self._step_fn()
                  ^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/loops/optimization/optimizer_loop.py", line 406, in _training_step
    training_step_output = self.trainer._call_strategy_hook("training_step", *kwargs.values())
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 1480, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py", line 378, in training_step
    return self.model.training_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/GRN/GRNformer/GRNFlow_Train.py", line 171, in training_step
    loss = self.loss_fn(grn_pred_edge,batch_targ_pos,batch_targ_neg,bath_targ)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/GRN/GRNformer/GRNFlow_Train.py", line 148, in recon_loss
    print(pos_loss+neg_loss)
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/_tensor.py", line 426, in __repr__
    return torch._tensor_str._str(self, tensor_contents=tensor_contents)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/_tensor_str.py", line 636, in _str
    return _str_intern(self, tensor_contents=tensor_contents)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/_tensor_str.py", line 567, in _str_intern
    tensor_str = _tensor_str(self, indent)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/_tensor_str.py", line 327, in _tensor_str
    formatter = _Formatter(get_summarized_data(self) if summarize else self)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/_tensor_str.py", line 115, in __init__
    nonzero_finite_vals = torch.masked_select(
                          ^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/home/aghktb/GRN/GRNformer/GRNFlow_Train.py", line 318, in <module>
    train_GRNFormerLinkPred()
  File "/home/aghktb/GRN/GRNformer/GRNFlow_Train.py", line 311, in train_GRNFormerLinkPred
    trainer.fit(model, train_loader, valid_loader)
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 603, in fit
    call._call_and_handle_interrupt(
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py", line 63, in _call_and_handle_interrupt
    trainer._teardown()
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py", line 1161, in _teardown
    self.strategy.teardown()
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py", line 496, in teardown
    self.lightning_module.cpu()
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/lightning/lite/utilities/device_dtype_mixin.py", line 78, in cpu
    return super().cpu()
           ^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 954, in cpu
    return self._apply(lambda t: t.cpu())
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 797, in _apply
    module._apply(fn)
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 820, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/home/aghktb/miniconda3/envs/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py", line 954, in <lambda>
    return self._apply(lambda t: t.cpu())
                                 ^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
tensor([[-0.0221,  0.1907, -0.0458,  0.2240],
        [-0.0288,  0.1981, -0.0501,  0.2282],
        [-0.0330,  0.1834, -0.0513,  0.2082],
        [-0.0296,  0.1822, -0.0475,  0.2065],
        [-0.0275,  0.1976, -0.0494,  0.2287],
        [-0.0222,  0.1906, -0.0458,  0.2237],
        [-0.0289,  0.1985, -0.0502,  0.2287],
        [-0.0271,  0.1779, -0.0467,  0.2043],
        [-0.0259,  0.1960, -0.0485,  0.2279],
        [-0.0257,  0.1835, -0.0461,  0.2115],
        [-0.0257,  0.1946, -0.0481,  0.2262],
        [-0.0240,  0.1904, -0.0465,  0.2218],
        [-0.0337,  0.1840, -0.0518,  0.2086],
        [-0.0307,  0.1813, -0.0495,  0.2067],
        [-0.0240,  0.1894, -0.0464,  0.2206],
        [-0.0246,  0.1917, -0.0470,  0.2232],
        [-0.0287,  0.1981, -0.0501,  0.2283],
        [-0.0271,  0.1971, -0.0492,  0.2284],
        [-0.0278,  0.1970, -0.0495,  0.2276],
        [-0.0241,  0.1905, -0.0466,  0.2219],
        [-0.0213,  0.1902, -0.0454,  0.2240],
        [-0.0241,  0.1901, -0.0466,  0.2216],
        [-0.0267,  0.1964, -0.0489,  0.2278],
        [-0.0240,  0.1904, -0.0465,  0.2218],
        [-0.0257,  0.1850, -0.0463,  0.2132],
        [-0.0330,  0.1834, -0.0513,  0.2082],
        [-0.0325,  0.1830, -0.0509,  0.2078],
        [-0.0297,  0.1823, -0.0476,  0.2065],
        [-0.0289,  0.1822, -0.0472,  0.2070],
        [-0.0244,  0.1911, -0.0469,  0.2224],
        [-0.0268,  0.1961, -0.0489,  0.2272],
        [-0.0338,  0.1841, -0.0519,  0.2087],
        [-0.0231,  0.1918, -0.0465,  0.2245],
        [-0.0328,  0.1832, -0.0511,  0.2081],
        [-0.0286,  0.1792, -0.0465,  0.2034],
        [-0.0240,  0.1897, -0.0464,  0.2209],
        [-0.0320,  0.1822, -0.0486,  0.2046],
        [-0.0276,  0.1968, -0.0494,  0.2275],
        [-0.0243,  0.1864, -0.0464,  0.2170],
        [-0.0280,  0.1971, -0.0496,  0.2275],
        [-0.0206,  0.1898, -0.0450,  0.2240],
        [-0.0323,  0.1849, -0.0492,  0.2079],
        [-0.0246,  0.1902, -0.0469,  0.2212],
        [-0.0316,  0.1821, -0.0502,  0.2073],
        [-0.0266,  0.1768, -0.0452,  0.2018],
        [-0.0328,  0.1832, -0.0511,  0.2080],
        [-0.0298,  0.1835, -0.0479,  0.2081],
        [-0.0246,  0.1917, -0.0470,  0.2232],
        [-0.0257,  0.1836, -0.0461,  0.2116],
        [-0.0321,  0.1826, -0.0506,  0.2076],
        [-0.0313,  0.1818, -0.0499,  0.2070],
        [-0.0241,  0.1912, -0.0467,  0.2228],
        [-0.0243,  0.1902, -0.0466,  0.2214],
        [-0.0299,  0.1817, -0.0476,  0.2056],
        [-0.0295,  0.1809, -0.0472,  0.2049],
        [-0.0287,  0.1980, -0.0501,  0.2282],
        [-0.0338,  0.1842, -0.0519,  0.2087],
        [-0.0289,  0.1816, -0.0471,  0.2063],
        [-0.0233,  0.1918, -0.0466,  0.2243],
        [-0.0315,  0.1857, -0.0490,  0.2096],
        [-0.0301,  0.1827, -0.0478,  0.2068],
        [-0.0268,  0.1969, -0.0490,  0.2284],
        [-0.0229,  0.1916, -0.0463,  0.2246],
        [-0.0297,  0.1803, -0.0487,  0.2060],
        [-0.0250,  0.1866, -0.0466,  0.2164],
        [-0.0285,  0.1978, -0.0499,  0.2281],
        [-0.0245,  0.1906, -0.0469,  0.2218],
        [-0.0229,  0.1914, -0.0463,  0.2241],
        [-0.0276,  0.1967, -0.0493,  0.2274],
        [-0.0257,  0.1832, -0.0461,  0.2111],
        [-0.0241,  0.1907, -0.0465,  0.2221],
        [-0.0260,  0.1951, -0.0483,  0.2265],
        [-0.0294,  0.1802, -0.0470,  0.2040],
        [-0.0337,  0.1865, -0.0501,  0.2089],
        [-0.0240,  0.1900, -0.0465,  0.2214],
        [-0.0318,  0.1823, -0.0503,  0.2073],
        [-0.0240,  0.1905, -0.0465,  0.2220],
        [-0.0261,  0.1898, -0.0471,  0.2190],
        [-0.0305,  0.1811, -0.0494,  0.2066],
        [-0.0240,  0.1900, -0.0464,  0.2213],
        [-0.0287,  0.1979, -0.0500,  0.2281],
        [-0.0230,  0.1914, -0.0463,  0.2242],
        [-0.0322,  0.1826, -0.0506,  0.2076],
        [-0.0339,  0.1876, -0.0504,  0.2103],
        [-0.0253,  0.1942, -0.0479,  0.2259],
        [-0.0225,  0.1912, -0.0461,  0.2243],
        [-0.0241,  0.1903, -0.0465,  0.2216],
        [-0.0241,  0.1879, -0.0464,  0.2189],
        [-0.0257,  0.1836, -0.0461,  0.2116],
        [-0.0297,  0.1988, -0.0506,  0.2285],
        [-0.0231,  0.1925, -0.0466,  0.2255],
        [-0.0323,  0.1827, -0.0507,  0.2077],
        [-0.0245,  0.1888, -0.0468,  0.2197],
        [-0.0241,  0.1901, -0.0465,  0.2213],
        [-0.0255,  0.1835, -0.0461,  0.2118],
        [-0.0240,  0.1867, -0.0464,  0.2176],
        [-0.0316,  0.1821, -0.0502,  0.2073],
        [-0.0325,  0.1830, -0.0509,  0.2079],
        [-0.0257,  0.1835, -0.0461,  0.2115],
        [-0.0297,  0.1991, -0.0507,  0.2289]], device='cuda:0')
samples: tensor([[ 1.3170e+00,  3.9591e-01, -1.7337e+00,  7.3429e-01],
        [-3.7461e-01,  8.4360e-01,  1.5234e+00,  5.8008e-01],
        [ 1.0968e+00,  1.9319e-01, -3.6610e-01,  6.8908e-01],
        [-1.2605e+00,  1.2723e+00,  1.0091e+00, -7.6821e-01],
        [-3.4900e-01, -1.4124e+00,  1.8824e+00, -3.2067e-01],
        [-2.0046e+00,  4.5739e-01,  8.5798e-01,  3.8412e-01],
        [-1.1901e-01,  1.2425e-01,  4.8790e-03,  8.4761e-01],
        [ 6.8942e-01,  6.4272e-01,  7.4538e-01, -1.9888e+00],
        [ 2.4977e-01, -8.8063e-01, -9.2101e-01,  2.0458e+00],
        [-4.7014e-01,  4.3429e-01,  4.3611e-01, -9.4669e-02],
        [-2.7595e+00, -3.3931e-01, -6.7168e-01, -1.0598e+00],
        [-1.3634e+00, -4.8149e-01,  1.1670e+00, -7.9818e-01],
        [-1.4255e-01,  1.7491e+00,  9.3318e-01, -1.0171e+00],
        [-1.2089e+00,  6.0956e-01,  5.4729e-01,  2.5436e-01],
        [ 1.5373e+00,  1.3217e+00, -1.5081e-01, -3.3800e-01],
        [ 1.1526e+00,  3.6560e-01,  1.1639e+00,  1.6630e+00],
        [ 1.7394e+00, -1.4843e+00,  1.2410e-01,  1.2269e+00],
        [ 1.5058e+00,  1.8223e-02, -3.9659e-01, -1.7392e+00],
        [ 1.0789e+00, -5.5195e-01,  2.3103e+00,  2.9578e-01],
        [-2.9618e+00, -1.1797e+00, -5.5435e-01,  9.4696e-01],
        [ 3.2888e-01,  2.9141e-01,  1.4699e+00, -9.3734e-01],
        [ 4.7872e-01,  6.2581e-01, -8.3599e-01,  1.1361e+00],
        [-3.5673e-01,  2.2581e-01,  2.5659e-01,  1.7788e+00],
        [-2.0463e+00,  5.4557e-01, -8.7747e-01, -4.4493e-01],
        [-1.9080e+00,  8.5974e-02, -4.8518e-01,  3.3341e-01],
        [ 1.5582e+00,  3.5146e-01,  7.5209e-01,  2.5570e-01],
        [ 9.6325e-01,  2.3622e+00, -5.0229e-01,  1.1087e+00],
        [-1.1153e+00,  4.0936e-01,  7.5405e-01,  1.1106e+00],
        [-1.9735e+00, -1.2399e+00,  7.5397e-01,  1.1202e+00],
        [-6.0919e-01,  6.5015e-01, -1.8930e-01,  3.8740e-01],
        [-1.5436e-02,  1.0434e+00, -4.6566e-01, -3.0506e-01],
        [-8.9653e-01,  4.8447e-01,  1.9171e-01,  1.5387e+00],
        [-2.2108e+00,  1.3979e+00,  2.4414e+00,  4.9989e-01],
        [-1.3019e+00,  5.4332e-01,  6.4340e-01,  1.2398e+00],
        [-6.3277e-01,  6.5405e-01,  4.4140e-01, -1.3126e+00],
        [-2.1252e-01,  7.4753e-01,  2.8852e-01, -7.8486e-01],
        [ 9.6460e-01,  1.3458e+00, -1.6148e+00, -1.2683e-01],
        [-4.4279e-01, -7.6156e-02, -7.2341e-01,  3.0248e+00],
        [ 6.2562e-01, -5.1428e-01, -6.7947e-01,  2.8769e-01],
        [-7.2375e-01,  1.3086e+00,  8.1750e-01,  1.2667e+00],
        [ 3.6404e-01, -7.7887e-01,  4.4985e-01, -8.1100e-02],
        [-9.7261e-01, -2.0254e-01,  4.0143e-01,  7.5360e-01],
        [-2.1401e+00,  1.5943e+00,  6.5962e-01,  8.1380e-01],
        [ 9.7209e-01,  3.4697e-01,  5.4229e-01, -1.0076e+00],
        [-8.4964e-01,  5.5298e-01,  5.7716e-01, -1.5825e+00],
        [ 1.5944e-06, -3.0067e-01,  7.9548e-02,  7.6299e-01],
        [ 5.1785e-01,  6.5912e-01, -1.6534e+00,  9.7478e-01],
        [ 2.2294e-01,  1.2117e-01,  2.1373e-01,  4.3541e-01],
        [-1.6732e+00,  1.2486e+00,  1.3179e+00, -8.8323e-01],
        [-5.4292e-01,  7.9134e-01, -6.4712e-02,  9.2557e-01],
        [ 1.4520e+00, -6.0008e-01, -2.2594e-01,  8.1788e-01],
        [-3.6862e-01,  6.5798e-01,  4.7883e-01,  4.4224e-01],
        [ 1.1966e+00, -7.1693e-01, -7.6309e-01, -1.1951e+00],
        [ 1.6748e-01,  1.0478e+00,  1.7416e+00, -1.2581e-01],
        [ 1.1453e+00,  1.0435e+00, -1.1549e+00, -3.0884e-01],
        [-1.2110e+00, -2.4735e-01, -5.5176e-02,  1.1122e+00],
        [-5.8049e-02,  9.4626e-01,  1.5267e+00, -1.3680e+00],
        [ 8.6958e-01,  3.7857e-01, -1.0506e-01,  1.2658e+00],
        [ 9.0837e-02,  5.5788e-01,  1.7050e+00,  9.1478e-01],
        [ 1.5957e+00, -1.2230e-01,  1.1977e-01,  1.8272e+00],
        [ 6.5823e-01,  1.2392e+00, -7.2867e-01,  1.6839e+00],
        [-9.1688e-01,  3.0306e-01,  2.2546e-01, -6.4636e-01],
        [-1.0009e+00,  2.5934e+00, -8.2825e-01, -9.1859e-02],
        [-8.4215e-01, -1.4329e+00,  4.2732e-01,  2.0851e-01],
        [-1.7899e+00, -6.8121e-01,  3.3248e-01,  3.5880e-01],
        [-1.0005e+00,  1.5837e-01, -1.4252e-01, -3.5894e-01],
        [-6.2188e-01, -1.8042e-01,  1.4695e+00,  1.3815e+00],
        [-8.4327e-01,  3.4210e-01, -1.9343e+00,  1.4525e+00],
        [-1.1518e+00, -1.3256e+00, -1.5854e+00,  1.1043e+00],
        [-1.9936e-02,  5.5166e-01, -1.3843e+00,  4.8241e-02],
        [-2.0038e-01,  2.8433e-01, -2.6222e-01,  8.2290e-01],
        [ 6.5828e-01,  4.3750e-01,  1.2454e-02,  1.2089e+00],
        [ 4.7416e-02, -4.0063e-02, -1.2242e+00, -2.3635e-01],
        [-5.7423e-01, -6.5720e-01, -1.6376e+00,  1.5793e+00],
        [-1.9364e+00, -1.2505e+00, -1.0908e+00, -4.0369e-01],
        [ 1.6636e+00, -4.1018e-01,  3.3396e-01,  5.4684e-02],
        [ 3.3982e-01,  1.6864e+00, -1.0313e+00,  1.3151e+00],
        [ 2.2838e-01, -1.0938e+00, -1.2738e+00,  4.6094e-01],
        [ 9.7250e-01, -1.8264e+00, -3.7106e-01, -1.0562e+00],
        [-9.1679e-01, -5.5438e-01,  3.6830e-03, -4.7553e-01],
        [-2.6970e+00, -2.0626e+00,  3.0467e-01,  2.5239e-02],
        [ 4.5985e-01,  4.6089e-01, -4.2215e-01,  7.5605e-01],
        [-2.2759e+00,  3.0736e-01, -8.4879e-01,  1.3247e-01],
        [ 3.9436e-01, -7.1186e-01,  1.6182e-01, -4.5555e-02],
        [ 1.0821e-01, -1.6602e+00,  6.2585e-01, -4.9354e-01],
        [ 6.9084e-01, -4.2504e-01, -7.9185e-01,  9.2280e-01],
        [-1.0029e+00,  1.1303e+00,  1.5439e+00,  1.2006e+00],
        [-2.6157e-01, -5.9250e-01,  4.0177e-01, -7.0033e-01],
        [-9.6388e-01, -7.4124e-01,  6.6787e-01,  2.2729e-01],
        [-1.4380e+00,  3.3746e-01,  1.7817e-01, -4.8869e-01],
        [ 4.8586e-01,  1.5278e+00,  2.0220e-01, -2.4285e-01],
        [-1.1492e-01, -4.4209e-01, -6.0541e-01,  6.8056e-01],
        [-1.2047e+00,  6.1559e-01, -6.0056e-01, -1.1580e-01],
        [ 1.6285e+00, -1.9047e+00, -1.3017e-01,  4.1382e-01],
        [-7.7094e-01, -1.9782e-01,  8.7710e-01,  4.3521e-01],
        [ 1.8593e-01,  3.8676e-01, -6.8875e-01, -5.0830e-01],
        [-4.5323e-02, -1.7895e-01,  8.2878e-01,  1.9653e+00],
        [ 7.3702e-01,  2.7720e+00,  8.8603e-01,  7.7712e-01],
        [ 3.5871e-01, -2.6248e-01, -6.3917e-01, -1.4724e+00],
        [ 2.9204e-01, -1.1333e+00, -1.4021e+00, -1.0429e+00]], device='cuda:0')
tensor([[-160.5135]], device='cuda:0')
tensor([[ 1.9061e+00, -2.4989e-01, -1.3814e-02,  2.0544e+00],
        [ 2.5385e-01, -1.4320e-01,  1.5292e+00,  1.2070e-01],
        [ 2.2837e+00, -2.8620e-01,  3.0552e-01,  1.8986e+00],
        [-1.1022e+00,  4.7483e+00, -8.0091e-01, -4.0184e-01],
        [-2.6702e+00, -1.5947e+00,  2.2935e+00, -6.4002e-01],
        [-1.3576e-03,  1.0349e+03, -1.1039e+01, -2.2817e-01],
        [ 3.5663e-01, -3.0153e-01, -1.2794e-01,  6.6586e-01],
        [-1.4735e+00,  7.0376e+00,  7.2563e-01, -1.5684e+00],
        [ 8.0648e-01, -7.6921e-02, -7.2553e-01,  4.5785e+00],
        [-5.6872e-01,  1.1446e+01, -3.9674e+00, -4.2869e-01],
        [-9.7846e-25,  2.6966e+16, -7.8724e+01, -8.4331e-01],
        [-4.8991e-01,  4.6583e+00, -2.9322e-01, -1.0493e+00],
        [-6.8542e-01,  1.7152e+00,  8.8518e-01, -4.1363e-01],
        [-3.1670e-01,  8.6841e+00, -2.5124e+00, -1.9277e-01],
        [ 3.4175e-01,  9.9534e+00, -2.2283e+00, -3.6081e-01],
        [ 1.0362e+00, -1.5905e+00,  1.0323e+00,  2.8193e+00],
        [ 6.0100e-01, -8.4386e-06,  4.2939e-01,  1.4323e+01],
        [-2.2029e-01,  1.0899e+01,  2.9556e-01, -1.8385e+00],
        [ 5.0839e+00, -2.2945e-01,  1.2732e+00,  2.3301e+00],
        [-9.1714e-02,  7.7927e+01, -6.3666e+00, -3.0907e-01],
        [-2.8072e-01,  4.2531e-01,  1.2846e+00, -7.7477e-01],
        [-3.8044e-02,  6.5942e+00, -1.7885e+00,  5.0383e-01],
        [ 4.1964e-01, -3.3071e-01, -1.8492e-01,  1.1290e+00],
        [-1.3025e+00,  1.1127e+01, -4.1636e+00, -8.8633e-01],
        [-1.0836e+00,  1.1421e+01, -4.4880e+00, -2.9853e-01],
        [ 3.0743e+00, -2.7211e-01,  4.9348e-01,  1.8029e+00],
        [ 1.5475e+00,  9.5330e-01,  2.5048e-01,  4.5453e-01],
        [-3.9020e-01,  1.8916e+00, -1.5408e+00,  1.9415e-01],
        [-3.8787e-06,  2.8780e+04, -1.9138e+01,  1.7628e-01],
        [-1.0044e-01,  6.4906e+00, -3.8725e-01,  1.7523e-01],
        [-2.5571e-01,  2.0640e+00, -2.3386e-01, -2.3814e-01],
        [-2.0024e-01,  1.6183e+00, -1.8599e+00,  4.6282e-01],
        [-2.7163e+00,  1.5107e+00,  1.8519e-01, -1.3285e-01],
        [-1.9967e-01,  6.5425e+00, -2.9107e+00,  1.6514e-01],
        [-1.4323e+00,  5.1009e+00, -3.4222e-01, -8.5636e-01],
        [-3.9250e-01,  8.2766e+00, -1.9542e+00, -9.4509e-01],
        [ 1.0063e+00,  1.0776e+00, -5.1653e-02,  1.4197e-01],
        [ 1.5185e-01, -3.1594e-01, -2.0595e+00,  2.3694e+00],
        [ 4.0002e-03,  3.9261e+00, -1.2639e+00,  1.0358e-01],
        [-5.5565e-01,  6.2062e-01,  3.0703e-01,  2.0582e-01],
        [ 1.2835e+00, -8.3450e-01,  5.9620e-01,  4.6212e-01],
        [-2.2362e-01,  2.6201e+00, -2.3602e+00,  1.7332e-01],
        [-1.7332e-01,  4.1942e+01, -2.5704e+00, -2.3002e-01],
        [ 9.2640e-01,  1.0735e+00,  6.0188e-01, -6.6111e-01],
        [-1.4117e+00,  8.2748e+00, -7.5714e-01, -9.9901e-01],
        [ 7.2122e-01, -5.3426e-01,  2.3621e-02,  9.7825e-01],
        [ 7.3394e-01, -7.6117e-02, -4.5641e-01,  9.8028e-01],
        [ 7.9036e-01, -1.7016e+00,  5.2793e-01,  1.3217e+00],
        [-5.1134e-01,  2.2085e+01, -7.0341e-01, -9.7401e-01],
        [-2.6001e-01,  1.2301e+00, -8.5886e-01,  2.3586e-01],
        [ 2.3052e+00, -3.6035e-02,  3.5210e-01,  5.0387e+00],
        [-1.3013e-01,  1.0335e+01, -1.0232e-01,  1.6535e-01],
        [ 9.8017e-01, -1.8733e+00, -8.1806e+00, -7.8803e-01],
        [ 1.2134e+00,  1.2573e-01,  1.4500e+00, -1.0371e-01],
        [ 1.3653e+00,  6.5090e-01,  1.0563e-01,  1.5489e-01],
        [-2.6454e-02,  2.8217e+01, -5.8773e+00,  3.1171e-01],
        [-1.7114e+00,  1.1773e+00,  1.4308e+00, -8.1801e-01],
        [ 2.2633e+00, -2.4635e-01,  3.8067e-01,  2.0163e+00],
        [ 2.8166e+00, -3.3059e-01,  1.5574e+00,  6.4582e-01],
        [ 2.0994e+00, -1.1056e-02,  3.9249e-01,  6.3426e+00],
        [ 1.4351e+00, -5.2070e-02,  1.1926e-01,  1.1595e+00],
        [-5.0607e-01,  1.0635e+01, -2.0351e+00, -6.3790e-01],
        [-2.5607e-01,  1.4857e+01, -2.5856e+00, -1.2167e-01],
        [-1.9547e-01,  1.8568e+00, -2.8173e+00, -8.1471e-02],
        [-2.9448e-01,  1.2136e+01, -3.4216e+00, -2.9260e-01],
        [-1.7323e-01,  2.5073e+01, -3.6594e+00, -5.2543e-01],
        [ 1.7188e-01, -3.3144e+00,  9.8638e-01,  1.7548e+00],
        [-1.2951e-02,  3.7879e+01, -6.5162e+00,  5.0085e-01],
        [-7.4050e-05,  1.1184e+03, -1.4203e+01,  8.8565e-01],
        [-4.5067e-01,  1.0492e+01, -1.2333e+01, -2.9957e-01],
        [-3.9702e-01,  6.1701e+00, -6.3743e+00, -9.7579e-02],
        [ 2.0167e+00, -2.8552e-01,  4.1056e-01,  1.5653e+00],
        [-1.8477e-01,  1.8945e+00, -1.1267e+00, -2.1418e-01],
        [-4.5339e-03,  1.6654e+00, -5.1385e+00,  1.5685e+00],
        [-6.1648e-01,  5.5530e+00, -4.0177e+00, -8.7057e-01],
        [ 2.9728e+00, -1.6964e-01,  4.3404e-01,  2.9978e+00],
        [-2.3969e-01,  9.0232e+00, -8.7430e+00,  2.1087e-01],
        [-4.8202e-02,  2.4941e+01, -1.9439e+01, -2.1894e-01],
        [-2.0989e-01, -1.7147e+00,  2.4284e-01, -1.2611e+00],
        [-1.0488e+00,  3.8469e+00, -4.6657e+00, -1.0670e+00],
        [-3.3628e-27,  1.1278e+18, -8.6593e+01, -1.2025e+00],
        [ 1.1427e+00, -2.4832e-01,  1.2585e-01,  8.7628e-01],
        [-2.5316e-11,  1.2889e+08, -3.6108e+01, -3.2568e-01],
        [ 1.1329e+00, -7.8742e-01,  3.8688e-01,  5.3020e-01],
        [-5.0918e-01, -1.9280e+00,  5.5402e-01, -5.7472e-01],
        [ 1.5858e+00, -2.6821e-01, -1.8176e-02,  2.5013e+00],
        [-2.0290e-01,  1.7047e+01, -1.3702e-01,  3.1853e-01],
        [-2.4208e-01,  8.1542e+00,  2.2095e-01, -6.9849e-01],
        [-6.3824e-01,  8.3547e+00, -2.4037e+00, -3.0587e-01],
        [-3.5115e-02,  1.2538e+02, -6.3161e+00, -5.4179e-01],
        [ 7.4026e-01,  1.1900e+00,  4.7540e-01, -9.3958e-02],
        [ 1.6499e-01, -4.8764e-01, -1.0245e+00,  8.5588e-01],
        [-4.8379e-01,  6.0402e+00, -5.7793e+00, -5.8605e-01],
        [ 5.1613e-01, -5.6077e-01, -6.5187e+00, -1.3596e-01],
        [-4.7890e-01,  8.0840e+00, -2.2210e+00, -2.1981e-01],
        [-3.0263e-01,  9.2865e+00, -4.9534e-01, -4.6512e-01],
        [ 2.2602e+00, -2.6043e-01,  8.0473e-01,  2.1574e+00],
        [ 1.5648e+00,  1.3850e+00,  6.0276e-01,  1.8857e-01],
        [-2.6652e-01,  8.6697e+00, -8.5207e+00, -8.6544e-01],
        [-9.6715e-01,  1.4348e+01, -1.1761e+00, -1.6931e+00]], device='cuda:0')
torch.Size([100, 100])
tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0') tensor([0.5061, 0.5060, 0.5061,  ..., 0.5124, 0.5144, 0.5218], device='cuda:0')
tensor(16.8329, device='cuda:0')
tensor([[-0.0250,  0.1858, -0.0464,  0.2154],
        [-0.0216,  0.1899, -0.0454,  0.2233],
        [-0.0250,  0.1855, -0.0461,  0.2147],
        [-0.0243,  0.1811, -0.0450,  0.2094],
        [-0.0302,  0.1823, -0.0478,  0.2062],
        [-0.0250,  0.1847, -0.0463,  0.2140],
        [-0.0307,  0.1813, -0.0494,  0.2066],
        [-0.0249,  0.1868, -0.0461,  0.2161],
        [-0.0250,  0.1861, -0.0465,  0.2157],
        [-0.0212,  0.1893, -0.0452,  0.2228],
        [-0.0248,  0.1757, -0.0448,  0.2026],
        [-0.0233,  0.1768, -0.0437,  0.2044],
        [-0.0221,  0.1906, -0.0458,  0.2238],
        [-0.0261,  0.1950, -0.0484,  0.2265],
        [-0.0242,  0.1853, -0.0457,  0.2150],
        [-0.0247,  0.1871, -0.0460,  0.2166],
        [-0.0313,  0.1818, -0.0500,  0.2071],
        [-0.0275,  0.1968, -0.0493,  0.2276],
        [-0.0249,  0.1875, -0.0462,  0.2169],
        [-0.0250,  0.1846, -0.0463,  0.2138],
        [-0.0254,  0.1890, -0.0470,  0.2190],
        [-0.0275,  0.1965, -0.0493,  0.2273],
        [-0.0279,  0.1971, -0.0496,  0.2277],
        [-0.0245,  0.1832, -0.0457,  0.2124],
        [-0.0282,  0.1985, -0.0499,  0.2293],
        [-0.0258,  0.1947, -0.0482,  0.2263],
        [-0.0318,  0.1856, -0.0491,  0.2092],
        [-0.0273,  0.1964, -0.0491,  0.2273],
        [-0.0241,  0.1871, -0.0459,  0.2171],
        [-0.0277,  0.1977, -0.0496,  0.2287],
        [-0.0276,  0.1973, -0.0494,  0.2283],
        [-0.0245,  0.1792, -0.0451,  0.2071],
        [-0.0313,  0.1818, -0.0500,  0.2071],
        [-0.0241,  0.1884, -0.0460,  0.2188],
        [-0.0240,  0.1818, -0.0449,  0.2103],
        [-0.0247,  0.1838, -0.0461,  0.2131],
        [-0.0245,  0.1797, -0.0452,  0.2078],
        [-0.0248,  0.1857, -0.0462,  0.2151],
        [-0.0278,  0.1788, -0.0461,  0.2034],
        [-0.0289,  0.1818, -0.0471,  0.2066],
        [-0.0271,  0.1962, -0.0490,  0.2272],
        [-0.0302,  0.1847, -0.0482,  0.2094],
        [-0.0276,  0.1969, -0.0494,  0.2276],
        [-0.0248,  0.1937, -0.0476,  0.2258],
        [-0.0267,  0.1959, -0.0488,  0.2271],
        [-0.0298,  0.1820, -0.0476,  0.2062],
        [-0.0247,  0.1868, -0.0463,  0.2168],
        [-0.0217,  0.1899, -0.0455,  0.2232],
        [-0.0241,  0.1928, -0.0471,  0.2250],
        [-0.0240,  0.1896, -0.0459,  0.2201],
        [-0.0303,  0.1809, -0.0491,  0.2063],
        [-0.0249,  0.1861, -0.0464,  0.2157],
        [-0.0251,  0.1827, -0.0459,  0.2112],
        [-0.0229,  0.1915, -0.0463,  0.2243],
        [-0.0242,  0.1807, -0.0450,  0.2090],
        [-0.0288,  0.1798, -0.0467,  0.2040],
        [-0.0266,  0.1770, -0.0457,  0.2027],
        [-0.0221,  0.1914, -0.0459,  0.2249],
        [-0.0291,  0.1794, -0.0468,  0.2032],
        [-0.0289,  0.1796, -0.0481,  0.2055],
        [-0.0222,  0.1908, -0.0459,  0.2240],
        [-0.0252,  0.1760, -0.0444,  0.2018],
        [-0.0305,  0.1816, -0.0478,  0.2050],
        [-0.0210,  0.1892, -0.0451,  0.2229],
        [-0.0223,  0.1905, -0.0458,  0.2236],
        [-0.0250,  0.1841, -0.0463,  0.2134],
        [-0.0250,  0.1855, -0.0464,  0.2149],
        [-0.0236,  0.1809, -0.0449,  0.2099],
        [-0.0279,  0.1970, -0.0495,  0.2275],
        [-0.0248,  0.1870, -0.0461,  0.2164],
        [-0.0249,  0.1869, -0.0461,  0.2162],
        [-0.0247,  0.1876, -0.0461,  0.2172],
        [-0.0245,  0.1792, -0.0451,  0.2071],
        [-0.0274,  0.1966, -0.0493,  0.2273],
        [-0.0306,  0.1835, -0.0482,  0.2075],
        [-0.0271,  0.1973, -0.0492,  0.2286],
        [-0.0324,  0.1829, -0.0508,  0.2078],
        [-0.0301,  0.1807, -0.0490,  0.2063],
        [-0.0244,  0.1866, -0.0460,  0.2165],
        [-0.0336,  0.1863, -0.0501,  0.2087],
        [-0.0311,  0.1817, -0.0498,  0.2070],
        [-0.0263,  0.1954, -0.0485,  0.2267],
        [-0.0266,  0.1958, -0.0487,  0.2270],
        [-0.0243,  0.1881, -0.0461,  0.2184],
        [-0.0286,  0.1979, -0.0500,  0.2282],
        [-0.0243,  0.1849, -0.0458,  0.2145],
        [-0.0210,  0.1899, -0.0452,  0.2239],
        [-0.0244,  0.1829, -0.0453,  0.2114],
        [-0.0262,  0.1951, -0.0484,  0.2265],
        [-0.0265,  0.1955, -0.0486,  0.2267],
        [-0.0309,  0.1821, -0.0481,  0.2053],
        [-0.0279,  0.1974, -0.0496,  0.2280],
        [-0.0315,  0.1825, -0.0484,  0.2054],
        [-0.0250,  0.1847, -0.0463,  0.2140],
        [-0.0295,  0.1802, -0.0485,  0.2059],
        [-0.0274,  0.1977, -0.0495,  0.2289],
        [-0.0279,  0.1969, -0.0495,  0.2274],
        [-0.0286,  0.1810, -0.0469,  0.2057],
        [-0.0240,  0.1818, -0.0449,  0.2103],
        [-0.0259,  0.1950, -0.0483,  0.2264]], device='cuda:0')
samples: tensor([[ 0.0388,  1.4910, -0.6688,  0.6458],
        [ 0.7735,  1.0662, -1.6807,  1.5201],
        [-0.1472,  0.2074, -0.1874, -0.5934],
        [ 0.9965,  1.2591,  1.3797,  2.2517],
        [-0.2866,  0.0616,  0.3183, -1.9142],
        [-0.2498, -1.8605,  0.3740,  0.6478],
        [-2.7914,  0.2458, -0.5569, -0.1796],
        [-0.6845,  3.1582,  0.5552, -0.4423],
        [-0.8147,  0.0117, -1.8831,  1.9803],
        [ 1.5738, -0.5663, -1.2826, -0.4500],
        [-0.6142,  0.0271,  0.4531, -0.3704],
        [-1.1145, -0.8553, -0.0502, -0.2458],
        [ 2.0366, -0.3240, -1.6098,  1.4892],
        [ 1.7967,  0.4335, -1.2810,  1.0547],
        [-1.2295,  1.4771,  0.6165, -0.0982],
        [-1.2006,  0.7682, -0.0050,  0.1504],
        [-1.4320, -1.0554,  0.1160, -0.3934],
        [ 0.9294, -0.0067,  0.2291,  0.1855],
        [-1.6184, -1.4810,  0.3726, -0.3990],
        [-0.6445,  1.0463, -0.7723,  0.0758],
        [ 0.2280,  0.6652,  2.8109, -0.0282],
        [-0.7099,  0.1787, -0.2871, -0.8043],
        [ 0.5678, -1.1846, -1.3203,  1.2299],
        [ 1.5646, -0.2221,  0.5530,  1.9602],
        [ 0.8105,  0.9643, -0.3413, -0.0203],
        [ 0.7320, -1.1887, -0.5030, -0.2655],
        [ 0.0331,  0.6350,  1.4011,  2.0554],
        [-1.1804,  0.9128,  0.1238, -0.1238],
        [-1.0421, -1.0891, -0.6340, -0.5706],
        [-0.1049,  0.3735,  0.0897,  0.1762],
        [ 0.9452, -0.3918, -0.3750, -0.2250],
        [-1.4036, -0.2955,  0.8366, -1.0954],
        [ 0.4175,  0.2279,  1.8246,  1.3013],
        [ 0.5693, -0.8867,  0.9908, -2.9551],
        [-1.5428, -1.6603,  0.0229,  0.9424],
        [ 1.5588, -0.0173,  1.1707, -0.1876],
        [-0.8279,  0.8244,  0.3521,  1.3387],
        [ 0.8684,  0.0245,  1.9099,  0.8791],
        [-1.5157,  0.3651, -0.2460,  0.4626],
        [ 0.5022,  1.4315, -1.0134,  0.6804],
        [ 1.2864,  1.1363,  0.0865, -0.8940],
        [ 1.0469,  0.3353,  1.5544, -1.6214],
        [ 0.6017,  0.0981,  0.3213, -0.1755],
        [ 0.8323, -0.1800, -0.4279, -0.7128],
        [-1.0042, -0.2690, -1.5182,  0.7273],
        [ 0.1927,  0.6285, -0.7138,  0.3752],
        [-0.4652, -1.1551,  0.4804,  0.7088],
        [ 0.9910, -0.0721,  0.4133,  1.1502],
        [-0.1108, -0.6748,  0.8033,  2.2823],
        [-0.4826,  0.5751,  0.4373,  1.0639],
        [-0.7713, -0.8511,  0.3449, -1.3238],
        [ 0.1565,  0.1288,  0.3009,  0.2148],
        [ 0.2871, -0.8208, -0.2203,  0.8221],
        [ 0.0510,  1.2671, -1.2518, -1.5553],
        [ 0.7312, -0.6703, -0.1430,  0.3072],
        [ 0.5164,  0.5697,  1.1263,  1.1808],
        [ 0.8610, -0.2889,  0.6860, -0.7712],
        [-0.4187,  0.4538, -0.5988, -0.0522],
        [ 1.7375, -1.5144, -0.4619, -0.7593],
        [ 0.7059,  0.6182,  1.5828,  0.6397],
        [-0.0503, -0.5695, -1.9290,  1.5527],
        [ 0.9835,  0.1515,  0.1318, -0.2577],
        [ 0.7961, -1.3082,  0.4051,  2.2169],
        [-1.5526, -1.5616, -0.6123,  1.7600],
        [-0.7554, -0.3115,  1.2089,  0.2013],
        [ 0.0354,  0.0744,  0.1987, -0.1944],
        [ 0.6632,  0.1355, -0.8689,  0.8112],
        [ 0.7678,  0.8645,  0.4345, -0.3430],
        [-1.2522,  1.5138,  1.1572,  0.4120],
        [ 0.8707, -0.8948,  1.4163,  0.4093],
        [ 0.0443,  0.2991, -0.5654, -0.4944],
        [-1.9894,  0.0282, -1.1021,  1.0836],
        [ 1.1411, -0.5640, -0.3050, -1.2064],
        [ 0.7563, -0.9344,  0.3288, -0.5297],
        [ 1.0721, -0.3200,  0.3812, -0.7035],
        [ 0.5554, -0.6612, -0.5818, -0.4123],
        [ 0.4331, -0.3711, -0.0494, -0.2363],
        [ 1.2159, -1.4166, -1.1308, -0.2107],
        [ 0.9890, -0.2348,  0.1589,  2.7793],
        [-0.2595, -0.1327, -0.7592,  0.0958],
        [ 0.4412,  1.3238, -1.4798,  0.1470],
        [ 0.5172,  0.4117,  0.3650, -0.9477],
        [-0.0933, -0.7390,  0.7549, -0.2200],
        [ 1.8690,  1.7676,  0.1254, -0.2300],
        [-0.0060, -1.9587, -0.1764, -0.3628],
        [-1.3813,  0.2900, -0.5813,  0.0718],
        [ 0.0811,  0.0134,  1.5028,  1.4147],
        [ 0.0937,  0.0653, -0.1813, -0.4801],
        [ 0.0778, -0.8755,  0.4174,  0.2716],
        [-0.0915,  1.1071,  0.0117, -0.5762],
        [ 0.5199, -1.1899,  0.3021,  0.1062],
        [-0.8773, -0.5488,  0.6068, -1.5153],
        [-0.4199, -0.0819,  0.1599,  0.7031],
        [-1.6782,  0.9013, -0.4050,  0.3664],
        [-0.6290, -0.3163, -0.1780, -0.7767],
        [ 0.3401, -1.3547, -0.9452, -0.9796],
        [-0.6473, -0.8363,  1.2341, -0.7907],
        [-0.0156,  0.7747, -1.0873,  1.5616],
        [ 0.0050, -0.2699, -0.7290,  1.8279],
        [-0.3027,  1.8002, -0.7255, -0.9187]], device='cuda:0')
tensor([[-95.7132]], device='cuda:0')
tensor([[-3.1268e-01,  3.8005e+00, -3.2426e+00, -3.5715e-02],
        [ 1.2122e+00, -9.2687e-02, -1.9232e-01,  1.3140e+00],
        [-3.4223e-01,  1.3702e+00, -2.4691e+00, -4.4398e-01],
        [ 1.4210e+00, -2.0684e+00,  1.0217e+00,  2.4951e+00],
        [-2.8598e+00,  1.2213e+01, -2.3896e-02, -1.7456e+00],
        [-4.9256e-01, -9.7891e-01, -2.3081e+00, -4.5144e-02],
        [-1.2114e-21,  2.3767e+14, -6.8826e+01, -3.9710e-01],
        [-6.7656e-01,  6.5986e+00, -7.8939e-01, -7.0274e-01],
        [-1.1425e+00,  1.1913e+00, -7.9959e+00,  7.2940e-01],
        [ 2.2403e+00, -4.8649e-01,  1.1249e-01,  1.5513e+00],
        [-9.2574e-01,  2.1083e+00, -5.4325e-01, -5.2435e-01],
        [-4.3926e-02,  1.0464e+02, -5.9995e+00, -7.4920e-01],
        [ 1.2637e+00, -1.5728e-03,  1.0155e-01,  8.7046e+00],
        [ 2.3411e+00, -9.8445e-02,  1.3704e-01,  3.5656e+00],
        [-9.7157e-01,  4.2120e+00, -7.7086e-01, -6.6557e-01],
        [-1.1146e+00,  2.4825e+00, -1.5188e+00, -3.4251e-01],
        [-3.1715e-03,  1.3500e+03, -1.0149e+01, -1.0227e+00],
        [ 2.2953e+00, -4.3003e-01,  5.1329e-01,  1.1021e+00],
        [-4.5993e-01,  8.1635e+00, -4.0452e+00, -1.0712e+00],
        [-6.8971e-01,  4.4669e+00, -3.8100e+00, -2.8168e-01],
        [ 1.2951e+00, -5.8732e-01,  3.0683e+00, -4.5224e-01],
        [-4.3741e-01,  1.4495e+01, -2.2586e+00, -7.7815e-01],
        [ 9.4239e-01, -6.4450e-02, -6.0388e-01,  4.8119e+00],
        [ 1.0648e+00, -1.3465e+00, -2.8937e-01,  7.0953e-01],
        [ 1.2744e+00,  3.5703e-01,  2.9001e-01,  2.2957e-01],
        [ 1.3828e+00, -8.6247e-01,  9.4324e-02,  9.6040e-01],
        [ 3.0065e+00, -2.6601e-01,  1.3239e+00,  1.3410e+00],
        [-2.1136e-01,  1.7610e+01, -3.2347e+00, -2.9007e-01],
        [-6.6790e-01, -7.2679e-01, -3.3853e+00, -8.3352e-01],
        [-5.4622e-02,  2.7854e-01,  3.4700e-02,  4.7086e-02],
        [ 1.7245e+00, -6.0589e-01,  2.8123e-01,  7.2350e-01],
        [-1.5581e+00,  8.9027e+00, -7.0336e-01, -1.6876e+00],
        [ 4.4252e+00, -2.8228e-01,  1.4636e+00,  1.5836e+00],
        [ 1.2107e-01,  1.1638e-01, -8.2190e-01, -1.4550e+00],
        [-2.6566e-01, -2.4177e+00, -2.0556e+00,  7.5556e-01],
        [ 8.9110e-01, -4.0819e-01,  1.2604e+00, -1.1118e-01],
        [ 4.3527e-02, -3.5284e-01,  7.0720e-02,  1.1840e+00],
        [ 5.2372e-01, -8.6107e-01,  1.3319e+00,  5.7456e-02],
        [-4.3635e-03,  3.6033e+02, -9.1370e+00, -1.6636e-01],
        [ 7.3161e-01,  7.1872e-01, -5.7495e-02,  3.8159e-01],
        [ 1.5648e+00,  1.4410e+00,  3.8377e-01, -3.0984e-01],
        [-2.1738e-01,  4.1570e+00,  9.0127e-01, -1.4504e+00],
        [ 1.2968e+00, -3.1663e-01,  5.5878e-01,  1.8117e-01],
        [ 7.1220e-01,  1.2227e-01,  2.3804e-01, -3.7339e-01],
        [-5.0584e-03,  1.5116e+02, -8.4320e+00,  1.5310e-01],
        [ 3.0458e-01,  3.9275e-01, -2.5845e-01,  2.8606e-01],
        [-4.3349e-01, -7.9510e-01, -1.0858e+00,  3.1193e-03],
        [ 2.8381e+00, -1.6334e-01,  5.7646e-01,  2.8810e+00],
        [ 2.2955e+00, -1.2474e-01,  6.9712e-01,  3.3860e+00],
        [-3.4613e-01,  3.4381e+00, -4.0962e-01,  4.5931e-01],
        [-1.0839e+00,  4.4364e+01, -2.0141e+00, -1.9377e+00],
        [-1.9696e-01,  1.5953e+00, -1.9472e+00, -1.2329e-01],
        [ 3.4730e-01, -2.1626e+00, -2.1232e-01,  9.3449e-01],
        [-5.9626e-01,  7.7033e+00, -6.9223e-01, -7.8143e-01],
        [ 2.6028e+00, -1.1093e+01, -1.7750e+00, -2.0977e-02],
        [ 2.8189e+00, -2.8755e-01,  9.6419e-01,  1.2315e+00],
        [ 1.1663e+00, -2.8433e-01,  7.2241e-01, -4.5386e-01],
        [-3.4092e-01,  3.7605e+00, -1.4403e+00, -2.1543e-01],
        [ 2.7596e+00, -3.0380e-01,  3.0121e-01,  2.5990e+00],
        [ 3.1548e+00, -2.9107e-01,  1.0754e+00,  8.8896e-01],
        [ 1.3091e-01, -4.4670e-01, -2.4881e+00,  2.2594e+00],
        [ 1.8622e+00, -3.3681e-01,  4.6897e-01,  3.8794e-01],
        [ 1.4590e+00, -6.0833e-04,  6.3865e-01,  9.6316e+00],
        [-1.5332e-06,  8.3531e+03, -1.9591e+01,  1.4529e+00],
        [-1.1925e+00, -4.6444e-01,  5.4680e-01, -1.4694e-01],
        [-3.2092e-01,  2.2397e+00, -1.8545e+00, -2.3098e-01],
        [ 1.2598e-01,  2.0882e+00, -3.4888e+00,  3.2924e-02],
        [ 1.9691e-01,  3.3745e+00, -2.8385e-01, -2.4362e-01],
        [-1.2330e+00,  2.1407e+00, -2.0107e-01, -1.0587e-01],
        [ 2.6268e-01, -1.5915e+00,  1.1314e+00, -1.6535e-02],
        [-1.9157e-01,  1.7872e+00, -2.5512e+00, -3.8797e-01],
        [-4.1445e+00,  8.5532e-01, -2.7322e+00,  2.8745e-01],
        [ 3.2761e-01,  2.5589e+00,  2.4102e-01, -1.1694e+00],
        [ 1.4556e+00, -1.0217e+00,  5.8717e-01,  7.4216e-02],
        [ 1.7051e+00, -4.9234e-01,  5.6395e-01, -1.2338e-01],
        [ 5.3244e-01, -6.4657e-01, -2.1595e-02, -1.2078e-02],
        [ 6.9836e-01, -5.3642e-01,  2.7820e-01,  9.2234e-02],
        [ 1.9353e+00, -2.3970e-01,  2.8099e-02,  2.9824e+00],
        [ 6.5831e-01,  1.1838e-01, -1.1368e+00,  6.5475e-01],
        [-2.0795e-01,  1.6855e+00, -1.4826e+00, -2.7817e-02],
        [ 3.5156e-01,  1.4716e+00, -3.3174e-01,  1.0467e-01],
        [-5.4636e-03,  1.3657e+00,  5.7273e-01, -7.0961e-01],
        [-3.0257e-01, -8.6043e-01,  6.4292e-01, -2.5009e-01],
        [ 1.1400e+00,  5.1839e+00, -1.2640e+00, -2.2671e-01],
        [-2.5499e-01, -2.0377e+00, -8.4000e-01, -2.7099e-01],
        [-4.1342e-01,  2.3024e+00, -5.2259e+00, -5.4655e-01],
        [ 3.6906e+00, -3.2037e-01,  1.4692e+00,  1.5026e+00],
        [ 2.5144e+00, -5.2859e+00, -2.0584e+00, -5.7034e-01],
        [ 9.8254e-01, -7.7914e-01,  3.8077e-01,  8.0577e-01],
        [-4.8456e-01,  2.0552e+00,  9.7922e-02, -3.7276e-01],
        [ 2.0808e+00, -5.5541e-01,  5.2386e-01,  1.5649e+00],
        [-1.3856e+00,  3.0183e+01, -1.5789e+00, -1.7935e+00],
        [-1.0018e-01, -1.4998e-01, -5.7678e-01,  4.1519e-01],
        [-1.3586e+00,  4.0279e+00, -3.6832e+00, -2.1661e-01],
        [-5.4641e-01,  1.3854e+01, -2.0659e+00, -9.7813e-01],
        [-1.1698e+00,  7.4156e+00, -7.3254e-01, -1.6528e+00],
        [-3.7974e+00,  5.4526e-01,  6.7574e-01, -1.2861e+00],
        [ 2.5815e-01,  1.8943e-01, -8.3042e-01,  8.7053e-01],
        [ 9.1367e-02,  3.2235e-01, -3.0346e+00,  2.0092e+00],
        [-5.1931e-01,  5.2706e+00, -7.0985e-01, -3.7028e-01]], device='cuda:0')
torch.Size([100, 100])
tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0') tensor([0.5078, 0.5068, 0.5076,  ..., 0.5076, 0.5058, 0.5096], device='cuda:0')
tensor(5.5146, device='cuda:0')
tensor([[-3.5528e-02, -3.8487e-01,  7.0484e-01, -1.4355e-01],
        [ 4.2607e+00,  2.1100e-01,  8.3233e+01, -8.9315e-01],
        [ 9.2253e-01, -6.0874e-01,  1.0085e+00, -1.0188e+00],
        [-3.3652e+00, -5.7161e+00, -8.4998e-01, -3.5945e+00],
        [ 1.5618e-02, -2.2629e-01,  6.6250e-01, -1.0392e-02],
        [ 1.6801e+00, -4.7814e-01,  2.3373e+00, -9.0089e-01],
        [ 3.4518e-02, -3.7669e-02,  5.8322e-01,  2.3756e-01],
        [-3.2477e+00, -5.7764e+00, -7.9287e-01, -3.6337e+00],
        [ 2.3022e+00, -6.3787e-01,  2.4080e+00, -9.5216e-01],
        [-9.3900e-02, -1.4049e+00,  2.9194e-01, -1.3001e+00],
        [-3.5716e+00, -5.2942e+00, -1.0519e+00, -3.7193e+00],
        [ 1.9549e-02, -2.5682e-01,  5.1283e-01, -9.7613e-02],
        [-1.0649e-01, -1.3249e+00,  4.2662e-02, -1.1264e+00],
        [-7.5381e-02, -1.2250e+00,  4.8150e-01, -1.0646e+00],
        [-5.2133e-02, -1.1424e+00,  4.1527e-01, -1.0112e+00],
        [-1.3700e-02, -3.4262e-01,  6.9715e-01, -1.1305e-01],
        [-5.3575e-03, -2.9428e-01,  6.8665e-01, -7.3153e-02],
        [ 1.4922e+00, -4.2999e-01,  3.4113e+00, -9.4184e-01],
        [ 2.0511e+00, -7.6171e-01,  5.2301e+00, -1.3058e+00],
        [-5.2135e-01, -9.9268e-01,  5.3258e-01, -5.2813e-01],
        [-8.1782e-02, -6.1132e-01,  7.2984e-01, -2.8990e-01],
        [-4.5545e-02, -4.1100e-01,  7.0803e-01, -1.6189e-01],
        [-3.2987e-01, -9.0100e-01,  6.2567e-01, -4.6861e-01],
        [ 4.3315e+00,  2.6974e-01,  8.9581e+01, -8.5419e-01],
        [-8.2750e-02, -1.0890e+00,  2.4666e-01, -1.0879e+00],
        [-9.6268e-01, -1.1757e+00,  3.1802e-01, -6.4697e-01],
        [ 3.9466e+00,  6.8139e-02,  6.0844e+01, -9.2379e-01],
        [ 2.3260e-02, -6.4495e-02,  6.1981e-01,  1.7872e-01],
        [-3.4575e+00, -6.2342e+00, -8.9486e-01, -3.9308e+00],
        [-2.9536e-01, -8.3720e-01,  6.4245e-01, -4.2719e-01],
        [-5.8491e-02, -1.2236e+00,  5.2027e-01, -9.8962e-01],
        [-3.8104e+00, -7.8400e+00, -1.1086e+00, -5.2067e+00],
        [ 5.8285e-03, -2.2914e-01,  6.6984e-01, -1.3431e-02],
        [ 4.9195e+00,  8.5422e-01,  1.6107e+02, -3.8443e-01],
        [-1.0826e-01, -6.2851e-01, -4.9515e-01, -8.3442e-01],
        [ 6.8632e-01, -5.5462e-01,  6.2931e-01, -9.6448e-01],
        [-1.0891e-01, -8.5290e-01, -3.8397e-01, -1.0824e+00],
        [-1.5141e-01, -7.0947e-01,  7.1243e-01, -3.4427e-01],
        [-6.4809e-02, -1.0905e+00,  2.6956e-01, -1.0760e+00],
        [-1.0902e-01, -9.7814e-01, -3.0531e-01, -1.2638e+00],
        [ 1.6682e+00, -4.8906e-01,  2.2266e+00, -8.7562e-01],
        [ 3.6275e-02, -1.7564e-01,  5.7363e-01,  4.7158e-02],
        [-9.1825e-01, -1.1199e+00,  3.3962e-01, -6.1069e-01],
        [-9.9704e-02, -8.1685e-01, -1.3147e-01, -9.9766e-01],
        [-8.8046e-02, -7.1769e-01,  7.4324e-01, -3.4961e-01],
        [-1.3660e-01, -7.2326e-01,  7.1963e-01, -3.5322e-01],
        [-3.6158e+00, -7.2238e+00, -9.7183e-01, -4.5733e+00],
        [-9.1212e-02, -7.4230e-01,  6.1123e-02, -8.4279e-01],
        [-1.0631e-01, -1.3979e+00,  2.7676e-01, -1.3045e+00],
        [ 5.1071e-02, -5.4502e-01, -7.1417e-01, -9.0761e-01],
        [-1.0894e-01, -7.5652e-01, -2.8202e-01, -9.7008e-01],
        [-3.4825e+00, -6.3815e+00, -9.0700e-01, -4.0265e+00],
        [-3.5434e+00, -6.7544e+00, -9.3660e-01, -4.2685e+00],
        [ 7.8762e-03, -9.4537e-02,  6.4225e-01,  1.2992e-01],
        [-1.0269e-01, -9.1293e-01,  8.3486e-02, -1.0184e+00],
        [ 3.9312e+00,  1.3915e-02,  5.9279e+01, -9.8490e-01],
        [ 4.8077e+00,  5.5659e-01,  1.4094e+02, -7.5145e-01],
        [ 3.5112e+00, -4.5321e-01,  4.4084e+00, -7.3736e-01],
        [-3.4079e+00, -5.9505e+00, -8.7074e-01, -3.7467e+00],
        [-1.9233e+00, -1.9678e+00, -1.4899e-01, -1.1611e+00],
        [ 1.8835e+00, -5.1497e-01,  2.0061e+00, -8.0382e-01],
        [ 8.7955e-01, -4.8510e-01,  1.5083e+00, -1.0014e+00],
        [ 3.6926e+00, -7.8030e-02,  4.6312e+01, -1.0013e+00],
        [-9.4984e-02, -7.2404e-01, -2.2550e-01, -9.0563e-01],
        [-1.2493e-02, -3.4984e-01,  4.5137e-01, -3.0896e-01],
        [-6.9889e-02, -1.3548e+00,  4.8117e-01, -1.1300e+00],
        [ 2.3570e+00, -4.0870e-01,  3.1646e+00, -7.4584e-01],
        [-3.3625e+00, -5.7015e+00, -8.4866e-01, -3.5850e+00],
        [-3.3956e+00, -5.8821e+00, -8.6476e-01, -3.7023e+00],
        [-3.3568e+00, -5.6710e+00, -8.4590e-01, -3.5652e+00],
        [-5.3626e-02, -4.8974e-01,  7.1932e-01, -2.1612e-01],
        [-1.0895e-01, -8.5161e-01, -3.5019e-01, -1.0438e+00],
        [-1.0879e-01, -1.3467e+00,  2.6450e-01, -1.2767e+00],
        [-1.5516e-01, -7.1029e-01,  7.1061e-01, -3.4481e-01],
        [-9.7993e-02, -6.9590e-01, -1.5110e-01, -8.5260e-01],
        [ 3.3944e-02, -1.5538e-01,  6.1347e-01,  7.2734e-02],
        [ 4.4137e+00,  3.3771e-01,  9.7424e+01, -8.0932e-01],
        [ 1.0061e-01, -8.2987e-01,  5.2231e-01, -7.9653e-01],
        [-2.4692e-03, -2.3615e-01,  6.7485e-01, -2.0395e-02],
        [-5.5573e-02, -2.6207e-01,  6.8241e-01, -4.4552e-02],
        [-1.4800e+00, -1.6507e+00,  6.6516e-02, -9.5533e-01],
        [-3.5209e+00, -6.6143e+00, -9.2566e-01, -4.1776e+00],
        [-5.9452e-01, -1.0241e+00,  4.9701e-01, -5.4855e-01],
        [ 4.3665e-01, -5.4216e-01,  1.2740e-01, -9.7799e-01],
        [-2.5911e-01, -7.8786e-01,  6.6007e-01, -3.9516e-01],
        [-5.8517e-02, -7.8966e-01, -3.1766e-02, -8.1329e-01],
        [ 1.3585e+00, -7.5464e-01,  1.4132e+00, -8.8786e-01],
        [ 1.1189e-02, -5.0604e-01, -5.9146e-01, -8.2387e-01],
        [-3.3846e+00, -5.8217e+00, -8.5943e-01, -3.6631e+00],
        [-3.8478e-02, -4.5802e-01,  7.1684e-01, -1.9643e-01],
        [ 1.4121e+00, -5.0229e-01,  3.0547e+00, -1.0331e+00],
        [-3.3019e-02, -7.3508e-01, -4.8260e-01, -9.7463e-01],
        [ 1.5300e+00, -4.1367e-01,  1.8001e+00, -7.5960e-01],
        [-2.9991e-02, -3.4567e-01,  6.9845e-01, -1.1370e-01],
        [-3.4658e-02, -3.6004e-01,  7.0070e-01, -1.2457e-01],
        [ 1.5023e+00, -5.2244e-01,  1.5084e+00, -7.7979e-01],
        [ 2.2289e+00, -4.8373e-01,  2.4282e+00, -7.5333e-01],
        [-1.7987e-01, -7.1918e-01,  6.9859e-01, -3.5057e-01],
        [-1.0885e-01, -9.3817e-01, -1.0941e-02, -1.0878e+00],
        [ 5.3017e+00,  8.6513e-01,  2.1862e+02, -6.6282e-01]], device='cuda:0',
       grad_fn=<CatBackward0>)
samples: tensor([[ 1.3036e+00, -1.7970e-01, -9.8308e-01,  3.6675e-01],
        [ 3.9149e+00,  8.5655e-01,  8.4806e+01, -5.4128e-01],
        [ 2.0523e+00, -5.9894e-01,  6.9366e-01, -5.3793e-01],
        [-4.5961e+00, -4.6260e+00,  2.0664e-01, -4.5692e+00],
        [-3.0591e-01, -1.8363e+00,  2.5944e+00, -5.5974e-01],
        [-3.0228e-01, -2.1133e-01,  3.2411e+00, -7.4048e-01],
        [-5.5581e-02, -1.1187e-01,  6.3835e-01,  8.5651e-01],
        [-2.5312e+00, -5.3116e+00, -8.2320e-04, -5.8267e+00],
        [ 2.5779e+00, -1.7145e+00,  1.5354e+00,  8.6573e-01],
        [-5.3839e-01, -1.1541e+00,  7.7413e-01, -1.6063e+00],
        [-6.3054e+00, -5.8282e+00, -1.6754e+00, -5.0053e+00],
        [-1.3198e+00, -9.2867e-01,  1.7264e+00, -1.1176e+00],
        [-2.1533e-01,  2.4014e-01,  1.0276e+00, -2.3521e+00],
        [-1.2535e+00, -7.9675e-01,  1.0783e+00, -1.0169e+00],
        [ 1.5091e+00, -1.0129e-02,  3.1088e-01, -1.5699e+00],
        [ 1.1635e+00, -1.6872e-01,  1.9081e+00,  1.3267e+00],
        [ 1.7628e+00, -1.9767e+00,  8.6085e-01,  9.2547e-01],
        [ 3.0251e+00, -6.0888e-01,  3.0639e+00, -2.9094e+00],
        [ 3.1578e+00, -1.5106e+00,  7.5898e+00, -1.2376e+00],
        [-3.4591e+00, -2.3629e+00,  2.4813e-02,  1.9689e-01],
        [ 2.6837e-01, -5.1015e-01,  2.2451e+00, -1.4513e+00],
        [ 4.5723e-01,  2.4668e-02, -8.1381e-02,  7.5258e-01],
        [-6.5986e-01, -8.7161e-01,  9.3116e-01,  1.0824e+00],
        [ 2.3093e+00,  6.2495e-01,  8.8750e+01, -1.5209e+00],
        [-1.9650e+00, -1.1881e+00, -1.9226e-01, -9.6772e-01],
        [ 6.2849e-01, -1.0077e+00,  1.1214e+00, -5.9944e-01],
        [ 4.9424e+00,  2.2474e+00,  6.0393e+01, -2.2911e-02],
        [-1.0623e+00,  1.6260e-01,  1.4214e+00,  1.0828e+00],
        [-5.4021e+00, -7.6563e+00, -9.3697e-02, -3.0177e+00],
        [-8.8014e-01, -3.7811e-01,  5.0000e-01, -2.6224e-01],
        [-4.7080e-02, -3.7631e-01,  1.0351e-01, -1.5219e+00],
        [-4.6731e+00, -7.5397e+00, -8.6502e-01, -3.8766e+00],
        [-2.1818e+00,  9.7703e-01,  3.1577e+00,  2.6192e-01],
        [ 3.6504e+00,  1.2143e+00,  1.6176e+02,  6.4729e-01],
        [-7.1244e-01, -1.5366e-01, -7.2434e-03, -2.3504e+00],
        [ 4.9782e-01,  3.2339e-03,  9.6425e-01, -1.9702e+00],
        [ 8.8774e-01,  3.1072e-01, -1.9501e+00, -1.4139e+00],
        [-5.6660e-01, -9.8241e-01,  3.8379e-02,  2.4530e+00],
        [ 5.8510e-01, -1.7912e+00, -3.6353e-01, -1.0052e+00],
        [-8.0477e-01,  1.3337e-01,  5.6178e-01, -2.2463e-01],
        [ 2.0529e+00, -1.4578e+00,  2.7215e+00, -1.1808e+00],
        [-9.0403e-01, -5.6305e-01,  1.0243e+00,  5.9288e-01],
        [-3.0337e+00,  2.8425e-01,  1.0461e+00, -1.8138e-02],
        [ 9.0398e-01, -6.5198e-01,  4.6101e-01, -2.2125e+00],
        [-9.1111e-01, -3.4153e-01,  1.3656e+00, -2.1339e+00],
        [-1.0380e-01, -1.2071e+00,  8.5028e-01,  2.0175e-01],
        [-3.0681e+00, -6.7482e+00, -2.5774e+00, -3.8065e+00],
        [ 1.5628e-01, -8.1282e-01,  3.2189e-01, -6.3057e-01],
        [-1.7539e+00, -3.3293e-01,  1.6407e+00, -2.3993e+00],
        [-4.5970e-01,  6.3709e-02, -7.2828e-01, -1.8965e-01],
        [ 1.3743e+00, -1.5384e+00, -4.5807e-01, -3.5919e-01],
        [-3.8270e+00, -5.9148e+00, -3.8151e-01, -3.8070e+00],
        [-2.3225e+00, -7.6615e+00, -1.6531e+00, -5.6850e+00],
        [ 2.0527e-01,  7.7161e-01,  2.4314e+00, -2.0147e-01],
        [ 1.0721e+00, -5.0385e-02, -1.0241e+00, -1.5322e+00],
        [ 2.7490e+00, -4.3143e-01,  5.9273e+01, -1.0093e-01],
        [ 4.7835e+00,  1.3187e+00,  1.4252e+02, -2.3281e+00],
        [ 4.4097e+00, -2.5624e-01,  4.3505e+00,  3.2211e-01],
        [-3.2937e+00, -5.5844e+00,  8.8082e-01, -3.0562e+00],
        [-2.9608e-01, -2.2758e+00,  1.9817e-02,  4.5643e-01],
        [ 2.5718e+00,  5.4153e-01,  1.3252e+00,  6.7333e-01],
        [-1.0582e-02, -3.7891e-01,  1.7827e+00, -1.8761e+00],
        [ 2.7146e+00,  2.3238e+00,  4.5530e+01, -1.3178e+00],
        [-9.0746e-01, -2.3372e+00,  2.5050e-01, -9.0313e-01],
        [-1.7774e+00, -1.2177e+00,  8.3043e-01, -1.6657e-01],
        [-1.0419e+00, -1.3942e+00,  3.8858e-01, -1.7170e+00],
        [ 1.7597e+00, -7.7972e-01,  4.6810e+00,  4.1377e-01],
        [-4.1828e+00, -5.5508e+00, -2.7367e+00, -2.3567e+00],
        [-4.5198e+00, -7.4044e+00, -2.4009e+00, -2.8254e+00],
        [-3.3511e+00, -5.3025e+00, -2.1841e+00, -3.7281e+00],
        [-2.2993e-01, -3.9611e-01,  5.0361e-01,  3.8471e-01],
        [ 5.7532e-01, -6.0917e-01, -2.8941e-01, -6.1444e-02],
        [-3.1989e-02, -1.5669e+00, -9.1269e-01, -1.7171e+00],
        [-6.9573e-01, -1.5540e+00, -8.7686e-01,  1.0256e+00],
        [-2.0104e+00, -2.1364e+00, -1.1954e+00, -1.4777e+00],
        [ 1.7293e+00, -7.4785e-01,  9.9774e-01, -7.9927e-02],
        [ 4.7775e+00,  1.8336e+00,  9.6439e+01,  2.8376e-01],
        [ 3.5511e-01, -2.1135e+00, -7.0438e-01, -5.5456e-01],
        [ 1.0006e+00, -2.2437e+00,  3.5316e-01, -1.2831e+00],
        [-9.4836e-01, -1.0065e+00,  7.3253e-01, -7.4141e-01],
        [-4.1484e+00, -3.9113e+00,  4.2122e-01, -1.1582e+00],
        [-3.0380e+00, -6.3448e+00, -1.3015e+00, -3.6457e+00],
        [-2.8382e+00, -8.9941e-01, -3.0116e-01, -6.2370e-01],
        [ 8.6486e-01, -1.4417e+00,  3.3965e-01, -1.2338e+00],
        [-1.2557e-01, -2.6422e+00,  1.3338e+00, -1.1146e+00],
        [ 6.5484e-01, -1.4060e+00, -7.7752e-01, -1.1483e-01],
        [ 3.7971e-01,  1.8533e-01,  3.0036e+00,  9.1080e-02],
        [-2.2632e-01, -1.2865e+00, -1.4330e-01, -1.7431e+00],
        [-4.3229e+00, -6.7466e+00, -1.4549e-01, -3.6474e+00],
        [-1.4469e+00, -3.1938e-01,  9.4565e-01, -9.1364e-01],
        [ 1.9210e+00,  8.3305e-01,  3.3035e+00, -1.5014e+00],
        [-1.1564e-01, -1.3599e+00, -1.0373e+00, -5.0178e-01],
        [ 3.4990e-01,  1.3090e-02,  1.2463e+00, -1.0951e+00],
        [ 1.6226e+00, -2.4404e+00,  6.1477e-01,  7.8837e-02],
        [-7.8013e-01, -7.4138e-01,  1.6239e+00,  9.8835e-02],
        [ 1.7123e+00, -3.2236e-01,  8.6603e-01, -1.5056e+00],
        [ 2.2152e+00, -8.4481e-01,  3.3072e+00,  1.0047e+00],
        [ 5.8969e-01,  1.8698e+00,  1.6355e+00,  2.1867e-01],
        [ 2.7552e-01, -1.3842e+00, -6.0403e-01, -2.7717e+00],
        [ 5.6234e+00, -4.6729e-01,  2.1727e+02, -1.9346e+00]], device='cuda:0')
tensor([[-17914.4453]], device='cuda:0', grad_fn=<MmBackward0>)
tensor([[ 2.1856e+00, -2.6527e-01,  1.4984e-01,  2.3410e+00],
        [ 5.8545e+00, -1.2627e-02,  1.2490e+00,  5.6902e+00],
        [ 2.3006e+01, -3.2018e+00,  9.2026e-01,  5.2250e-01],
        [-0.0000e+00,         inf, -1.9949e+03, -1.3715e+01],
        [-1.4141e+01, -2.1334e+00,  3.7675e+00, -1.2829e+00],
        [ 8.7147e+00, -1.0601e+03,  1.1971e+00, -1.1270e+00],
        [ 1.1124e+00, -4.8842e-01,  5.9606e-01,  8.8072e-01],
        [-0.0000e+00,         inf, -1.7292e+02, -5.7195e+01],
        [ 1.9649e+01, -2.5149e+02,  2.1243e+00,  1.7364e+00],
        [-2.3236e+00, -9.0292e+00,  4.4404e-01, -2.8554e+00],
        [-0.0000e+00,         inf, -2.5536e+04, -1.5493e+01],
        [-3.5931e+00,  6.6780e+00, -2.5483e-01, -1.6501e+00],
        [ 8.1626e+00, -9.8637e+01,  7.8534e-01, -3.8981e+00],
        [-2.3995e+00, -5.2074e+00, -4.9124e-02, -1.9259e+00],
        [ 3.7532e+00, -3.1650e+00,  5.3795e-01, -1.7510e+00],
        [ 4.0180e+00, -6.9878e-02,  1.0074e+00,  3.8855e+00],
        [ 3.4027e-01, -2.2943e-07,  6.2325e-01,  1.8064e+01],
        [ 4.9455e+01, -1.2675e+01,  1.7022e+00, -3.2532e+00],
        [ 4.5407e+01, -1.4475e+00,  8.8048e-01,  1.0140e+00],
        [-0.0000e+00,         inf, -2.8131e+02, -1.1911e+00],
        [-7.7786e+00,  1.0074e+00,  2.0751e+00, -1.9328e+00],
        [ 1.5181e+00, -4.0720e-01,  2.9491e-01,  1.2292e+00],
        [ 2.1940e-01, -7.2235e-01, -8.6181e-02,  1.0738e+00],
        [ 8.2362e+02, -3.2249e-01,  7.1864e+00, -6.6632e-01],
        [-8.0762e+00, -1.0525e+00, -5.3232e+00, -2.4436e+00],
        [ 1.5097e+00, -1.1749e+00,  1.0790e+00, -2.6128e-01],
        [ 2.8192e+00, -9.8945e-03,  2.3816e-01,  6.0701e+00],
        [-9.6679e-01, -2.8303e-01,  4.7894e-01,  2.5374e-01],
        [-0.0000e+00,         inf, -1.1237e+04, -4.9099e+01],
        [-5.7241e-01,  5.3723e+00, -1.7398e+00, -5.8147e-01],
        [-1.3456e+00,  1.3417e+00, -1.1566e+00, -2.5321e+00],
        [-0.0000e+00,         inf, -5.0292e+03, -7.0824e+01],
        [-7.3583e+01, -2.9346e-01,  5.5799e+00, -2.0641e-01],
        [ 1.6757e+01, -3.2837e-03,  2.8382e+00,  6.6019e+00],
        [ 3.2129e+00, -1.1893e+03, -6.7876e-01, -6.8423e+00],
        [ 1.2091e+01, -8.9795e+00,  7.9144e-01, -2.2351e+00],
        [ 1.3463e+01, -5.3506e+00, -2.0175e-01, -1.2287e+00],
        [ 2.2524e-01, -2.8784e-01, -1.8544e+00,  3.2601e+00],
        [ 3.5276e+00, -2.3445e+00, -4.6930e-02, -9.9743e-01],
        [ 7.9347e+00, -1.4186e+00,  1.2362e-01, -5.8038e-01],
        [ 1.7295e+01, -2.0224e+02,  3.3643e+00, -7.2785e-01],
        [-5.7045e-01, -4.2668e-01, -5.2226e-01,  1.6089e-01],
        [-2.6662e-18,  2.2980e+12, -5.8293e+01, -3.4091e-01],
        [ 9.7378e+00, -2.3168e+03,  4.3744e-02, -3.4874e+00],
        [-6.7464e+00,  1.1013e+01,  5.4142e-01, -2.0829e+00],
        [ 9.5350e-01, -9.3107e-01,  7.0644e-01,  6.6211e-01],
        [-0.0000e+00,         inf, -7.5758e+02, -7.7572e+01],
        [ 3.8977e+00, -2.1652e+02, -1.5940e+00, -2.6504e+00],
        [-4.6010e+00, -1.1650e+01, -3.8038e-01, -3.6334e+00],
        [ 1.1453e+01, -6.7297e-01,  4.7793e-02,  6.4053e-01],
        [ 1.1477e+01, -7.5796e+00,  3.2216e-01,  5.8244e-01],
        [-0.0000e+00,         inf, -1.1449e+03, -3.5493e+01],
        [-0.0000e+00,         inf, -3.2766e+02, -2.5715e+02],
        [ 2.3013e+00, -1.8207e-01,  1.9454e+00, -1.3540e-01],
        [ 1.0945e+01, -9.9577e+00, -6.3398e-01, -1.6781e+00],
        [ 2.9654e+01, -1.4342e-03,  3.8467e+00,  7.3254e+00],
        [ 8.3503e+00,  5.7739e-02,  7.5742e-01,  5.8552e-01],
        [ 2.2635e+01, -1.8836e+01,  4.9254e+00,  1.2521e+00],
        [-0.0000e+00,         inf, -4.1587e+02, -2.9781e+01],
        [ 2.3361e-01, -7.4916e-01, -1.6866e+00,  2.3288e+00],
        [ 1.5463e+01, -1.3425e+02,  1.9098e+00,  1.4285e+00],
        [ 1.8423e+01, -6.8882e+00,  7.4141e-01, -3.0540e+00],
        [ 1.1647e+01,  6.9350e-01,  1.7800e+00, -1.2499e-01],
        [ 4.6756e+00, -1.9768e+03, -6.0246e-01, -2.8187e+00],
        [-4.7765e-04,  4.6196e+03, -1.2882e+01, -9.0706e-01],
        [-2.5635e+00, -6.4457e+00, -1.4131e+00, -2.9098e+00],
        [ 1.7024e+01, -1.2812e+01,  4.7083e+00,  1.3337e+00],
        [-0.0000e+00,         inf, -2.2220e+03, -1.8106e+01],
        [-0.0000e+00,         inf, -4.8572e+03, -5.5357e+01],
        [-0.0000e+00,         inf, -7.2357e+02, -2.8634e+01],
        [ 1.5999e-01, -6.0524e-01,  2.0561e-01,  3.6364e-01],
        [ 1.0040e+01, -4.5277e+00,  2.1946e-01,  1.4476e+00],
        [-3.9323e-01, -8.4825e+00, -8.0388e-01, -2.8497e+00],
        [-4.2589e-03,  6.6684e-01, -5.7591e+00,  1.6782e+00],
        [ 1.6530e-01, -3.0295e+03, -1.7025e+00, -4.9359e+00],
        [ 3.2140e+00, -1.0608e-01,  5.6408e-01,  3.6603e+00],
        [ 2.3519e+00, -1.7772e-03,  4.7322e-01,  8.1489e+00],
        [ 5.8993e+00, -1.3739e+02, -3.1034e+00, -1.0488e+00],
        [-4.0914e+00,  4.8843e+00,  6.3531e-01, -2.6839e+00],
        [-8.1907e-01,  1.7316e+01, -2.0280e+00, -1.3538e+00],
        [-0.0000e+00,         inf, -9.2336e+02, -4.8262e+00],
        [-0.0000e+00,         inf, -5.5179e+02, -5.9228e+01],
        [-5.8875e-29,  9.1018e+18, -9.2010e+01, -9.4480e-01],
        [ 2.7166e+01, -2.4658e+00,  6.6436e-01, -5.8378e-01],
        [-2.5902e+01,  3.8602e+01,  1.3324e+00, -4.0522e+00],
        [ 7.4603e+00, -2.4444e-01,  2.0836e-01,  4.5345e+00],
        [ 5.1404e+00, -2.5509e+01,  2.9110e+00, -1.3339e-02],
        [ 7.1588e+00, -2.4441e+01,  2.5208e-01, -2.6489e+00],
        [-0.0000e+00,         inf, -2.4787e+03, -4.7567e+01],
        [-1.8513e-01,  6.0629e+01, -4.2328e+00, -1.0252e+00],
        [ 3.4973e+01, -8.2147e+00,  1.1052e+00, -6.7310e-01],
        [ 1.2588e+01, -1.7385e+00,  9.3268e-02,  1.0524e+00],
        [ 1.4420e+01, -5.0875e+00,  8.8458e-01, -8.5461e-01],
        [ 7.6252e-01, -1.2651e-05,  6.4141e-01,  1.3863e+01],
        [-2.0909e+00, -9.8667e-01,  1.4119e+00, -2.4961e-01],
        [ 1.2627e+01, -8.3434e+02,  1.1450e+00, -1.7747e+00],
        [ 1.3439e+01, -2.5818e+01,  3.5504e+00,  2.1585e+00],
        [ 1.8657e+00,  6.4237e-01,  9.9331e-01,  1.0892e-01],
        [-3.6766e-01, -5.4639e+01, -2.6853e-02, -4.5170e+00],
        [ 9.7894e-02, -2.4267e-10,  6.8524e-01,  2.5099e+01]], device='cuda:0',
       grad_fn=<CatBackward0>)
torch.Size([100, 100])
tensor([[nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        ...,
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan],
        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',
       grad_fn=<SigmoidBackward0>)
tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0') tensor([nan, nan, nan,  ..., nan, nan, nan], device='cuda:0',
       grad_fn=<ViewBackward0>)